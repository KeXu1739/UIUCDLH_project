There are 764288 rows in the df after padding
(54592, 14)
(54592, 14, 224)
(224,)
(224,)
(54592, 14, 224)
(54592, 14, 224)
(54592, 14, 1)
[   62    66    72 ... 38178 38179 38197]
[   62    66    72 ... 38178 38179 38197]
[    0     1     2 ... 38211 38212 38213]
There are 764288 rows in the df after padding
There are 764288 rows in the df after padding
(54592, 14)
(54592, 14, 228)
(228,)
(228,)
(54592, 14, 228)
(54592, 14, 228)
(54592, 14, 1)
[    0     1     2 ... 38207 38208 38209]
[    0     1     2 ... 38207 38208 38209]
[    3     4     5 ... 38211 38212 38213]
There are 764288 rows in the df after padding
There are 764288 rows in the df after padding
(54592, 14)
(54592, 14, 227)
(227,)
(227,)
(54592, 14, 227)
(54592, 14, 227)
(54592, 14, 1)
[    0     1     6 ... 38207 38208 38213]
[    0     1     6 ... 38207 38208 38213]
[    2     3     4 ... 38210 38211 38212]
There are 764288 rows in the df after padding
time_steps:14|no_feature_cols:224
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 14, 224)]    0           []                               
                                                                                                  
 permute (Permute)              (None, 224, 14)      0           ['input_1[0][0]']                
                                                                                                  
 reshape (Reshape)              (None, 224, 14)      0           ['permute[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 224, 14)      210         ['reshape[0][0]']                
                                                                                                  
 attention_vec (Permute)        (None, 14, 224)      0           ['dense[0][0]']                  
                                                                                                  
 multiply (Multiply)            (None, 14, 224)      0           ['input_1[0][0]',                
                                                                  'attention_vec[0][0]']          
                                                                                                  
 masking (Masking)              (None, 14, 224)      0           ['multiply[0][0]']               
                                                                                                  
 lstm (LSTM)                    (None, 14, 256)      492544      ['masking[0][0]']                
                                                                                                  
 time_distributed (TimeDistribu  (None, 14, 1)       257         ['lstm[0][0]']                   
 ted)                                                                                             
                                                                                                  
==================================================================================================
Total params: 493,011
Trainable params: 493,011
Non-trainable params: 0
__________________________________________________________________________________________________

 1/96 [..............................] - ETA: 15:28 - loss: 0.4638 - acc: 0.6159
 2/96 [..............................] - ETA: 5s - loss: 0.4466 - acc: 0.6195   
 5/96 [>.............................] - ETA: 2s - loss: 0.3726 - acc: 0.7249
 7/96 [=>............................] - ETA: 2s - loss: 0.3637 - acc: 0.7500
10/96 [==>...........................] - ETA: 2s - loss: 0.3335 - acc: 0.7534
13/96 [===>..........................] - ETA: 2s - loss: 0.3235 - acc: 0.7546
16/96 [====>.........................] - ETA: 2s - loss: 0.3113 - acc: 0.7652
19/96 [====>.........................] - ETA: 1s - loss: 0.3033 - acc: 0.7664
22/96 [=====>........................] - ETA: 1s - loss: 0.2981 - acc: 0.7727
24/96 [======>.......................] - ETA: 1s - loss: 0.2915 - acc: 0.7754
27/96 [=======>......................] - ETA: 1s - loss: 0.2858 - acc: 0.7807
30/96 [========>.....................] - ETA: 1s - loss: 0.2788 - acc: 0.7816
33/96 [=========>....................] - ETA: 1s - loss: 0.2720 - acc: 0.7860
36/96 [==========>...................] - ETA: 1s - loss: 0.2688 - acc: 0.7902
39/96 [===========>..................] - ETA: 1s - loss: 0.2637 - acc: 0.7938
42/96 [============>.................] - ETA: 1s - loss: 0.2608 - acc: 0.7947
45/96 [=============>................] - ETA: 1s - loss: 0.2584 - acc: 0.7939
48/96 [==============>...............] - ETA: 1s - loss: 0.2570 - acc: 0.7941
51/96 [==============>...............] - ETA: 1s - loss: 0.2576 - acc: 0.7949
54/96 [===============>..............] - ETA: 0s - loss: 0.2542 - acc: 0.7958
57/96 [================>.............] - ETA: 0s - loss: 0.2546 - acc: 0.7945
60/96 [=================>............] - ETA: 0s - loss: 0.2523 - acc: 0.7958
63/96 [==================>...........] - ETA: 0s - loss: 0.2507 - acc: 0.7960
66/96 [===================>..........] - ETA: 0s - loss: 0.2503 - acc: 0.7975
69/96 [====================>.........] - ETA: 0s - loss: 0.2502 - acc: 0.7984
72/96 [=====================>........] - ETA: 0s - loss: 0.2502 - acc: 0.7982
75/96 [======================>.......] - ETA: 0s - loss: 0.2496 - acc: 0.7983
78/96 [=======================>......] - ETA: 0s - loss: 0.2500 - acc: 0.7970
81/96 [========================>.....] - ETA: 0s - loss: 0.2478 - acc: 0.7976
84/96 [=========================>....] - ETA: 0s - loss: 0.2485 - acc: 0.7974
87/96 [==========================>...] - ETA: 0s - loss: 0.2478 - acc: 0.7985
90/96 [===========================>..] - ETA: 0s - loss: 0.2457 - acc: 0.7993
93/96 [============================>.] - ETA: 0s - loss: 0.2446 - acc: 0.7991
96/96 [==============================] - ETA: 0s - loss: 0.2443 - acc: 0.7989
96/96 [==============================] - 17s 77ms/step - loss: 0.2443 - acc: 0.7989 - val_loss: 0.2166 - val_acc: 0.7777
TARGET: MI

  1/171 [..............................] - ETA: 6:04
  6/171 [>.............................] - ETA: 1s  
 11/171 [>.............................] - ETA: 1s
 16/171 [=>............................] - ETA: 1s
 21/171 [==>...........................] - ETA: 1s
 27/171 [===>..........................] - ETA: 1s
 32/171 [====>.........................] - ETA: 1s
 37/171 [=====>........................] - ETA: 1s
 42/171 [======>.......................] - ETA: 1s
 47/171 [=======>......................] - ETA: 1s
 52/171 [========>.....................] - ETA: 1s
 57/171 [=========>....................] - ETA: 1s
 63/171 [==========>...................] - ETA: 1s
 68/171 [==========>...................] - ETA: 1s
 73/171 [===========>..................] - ETA: 1s
 78/171 [============>.................] - ETA: 0s
 83/171 [=============>................] - ETA: 0s
 88/171 [==============>...............] - ETA: 0s
 93/171 [===============>..............] - ETA: 0s
 98/171 [================>.............] - ETA: 0s
103/171 [=================>............] - ETA: 0s
108/171 [=================>............] - ETA: 0s
113/171 [==================>...........] - ETA: 0s
118/171 [===================>..........] - ETA: 0s
123/171 [====================>.........] - ETA: 0s
128/171 [=====================>........] - ETA: 0s
133/171 [======================>.......] - ETA: 0s
138/171 [=======================>......] - ETA: 0s
143/171 [========================>.....] - ETA: 0s
148/171 [========================>.....] - ETA: 0s
153/171 [=========================>....] - ETA: 0s
158/171 [==========================>...] - ETA: 0s
163/171 [===========================>..] - ETA: 0s
168/171 [============================>.] - ETA: 0s
171/171 [==============================] - 4s 10ms/step

 1/48 [..............................] - ETA: 1s
 6/48 [==>...........................] - ETA: 0s
11/48 [=====>........................] - ETA: 0s
16/48 [=========>....................] - ETA: 0s
21/48 [============>.................] - ETA: 0s
26/48 [===============>..............] - ETA: 0s
31/48 [==================>...........] - ETA: 0s
36/48 [=====================>........] - ETA: 0s
41/48 [========================>.....] - ETA: 0s
46/48 [===========================>..] - ETA: 0s
48/48 [==============================] - 1s 11ms/step
Confusion Matrix Validation
[[34948  9931]
 [  123   217]]
Validation Accuracy
0.7776598332559322
ROC AUC SCORE VAL
0.8025460945313084
CLASSIFICATION REPORT VAL
              precision    recall  f1-score   support

         0.0       1.00      0.78      0.87     44879
         1.0       0.02      0.64      0.04       340

    accuracy                           0.78     45219
   macro avg       0.51      0.71      0.46     45219
weighted avg       0.99      0.78      0.87     45219

